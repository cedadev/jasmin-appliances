---
#####
## Playbook that provisions and then configures a Kubernetes
## cluster on OpenStack
#####

# Provision the cluster infrastructure
- hosts: openstack
  tasks:
    - import_tasks: tasks/install-dependencies.yml

    # Add the identity stack to the cluster and configure it as the gateway
    - include_role:
        name: jasmin.cluster-infra
      vars:
        cluster_name: "{{ identity_stack_name }}"
        cluster_stack_update: false
        cluster_gw_group: "{{ identity_gw_group_name }}"

    # Provision the Kubernetes infrastructure
    - import_tasks: tasks/infra/provision.yml
      vars:
        # These are the groups to use when no fixed IP is given
        cluster_groups: "{{ k8s_groups_no_ip }}"
        # These are the groups to use when a fixed IP is given
        cluster_groups_fixed_ip: "{{ k8s_groups_fixed_ip }}"
        # Tag to assign to the cluster
        cluster_tag: "{{ cluster_type.kubernetes }}"

# Gather facts for all hosts
- hosts: cluster
  tasks: []

- hosts: rke_hosts
  become: true
  tasks:
    - include_tasks: tasks/kubernetes/upgrade_os_packages.yml
    # Before installing Kubernetes, enroll as a FreeIPA client
    - include_tasks: tasks/identity/freeipa/client.yml

# Set the permissions for the cluster in FreeIPA
# We don't create a user group
# The admins group is granted the cluster-admin role via OIDC below
- hosts: freeipa_servers
  become: true
  tasks:
    - include_tasks: tasks/identity/freeipa/cluster_permissions.yml
      vars:
        create_user_group: false

# Create/delete the OIDC client for the cluster
- hosts: keycloak_servers
  become: true
  tasks:
    - include_tasks: tasks/identity/keycloak/oidc_client.yml
      vars:
        keycloak_client_id: cluster-{{ cluster_name | replace('_', '-') }}
        keycloak_client_name: "Kubernetes Cluster: {{ cluster_name }}"
        keycloak_client_description: >
          Client for connecting to Kubernetes cluster '{{ cluster_name }}'.
        keycloak_client_redirect_uris:
          - http://localhost:8000
          - urn:ietf:wg:oauth:2.0:oob

# Install Kubernetes
- hosts: rke_hosts
  become: true
  pre_tasks:
    # Before starting, make sure that we have an Openstack trust
    # This is created on the Openstack host but persisted on the cluster nodes
    - include_tasks: tasks/util/os_trust.yml
  roles:
    # Install Kubernetes using RKE
    - role: jasmin.rke
      vars:
        # In order to consume a single floating IP, we want to schedule the ingress controllers
        # on the controlplane nodes
        # However RKE doesn't allow us to specify tolerations
        # So we don't deploy ingress with RKE at all and deploy with Helm later
        rke_ingress_config: { provider: none }
        rke_cloud_provider: openstack
        openstack_trust_id: "{{ ansible_local.openstack_trust_id }}"
        openstack_project_id: "{{ ansible_local.openstack_project_id }}"
        # Configure the API server to authenticate using Keycloak
        rke_extra_config:
          services:
            kube-api:
              extra_args:
                oidc-issuer-url: "{{ hostvars[groups.keycloak_servers | first].keycloak_oidc_issuer_url }}"
                oidc-client-id: "{{ hostvars[groups.keycloak_servers | first].keycloak_client_id }}"
                oidc-username-claim: preferred_username
                oidc-username-prefix: "oidc:"
                oidc-groups-claim: groups
                oidc-groups-prefix: "oidc:"
        # Add a cluster-role-binding granting cluster-admin for the oidc:admins group
        rke_extra_addons: |
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: oidc-admins-cluster-admin
          subjects:
            - apiGroup: rbac.authorization.k8s.io
              kind: Group
              name: oidc:admins
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: cluster-admin
  tasks:
    # On the first host in the play, install Helm and the Ingress controller
    - block:
        # Install Helm
        - include_role:
            name: jasmin.helm

        # Install the Nginx ingress controller on the controlplane nodes
        - include_role:
            name: jasmin.helm
            tasks_from: chart.yml
          vars:
            helm_release_name: nginx-ingress-controller
            helm_release_chart: stable/nginx-ingress
            helm_release_namespace: nginx-ingress
            helm_release_values:
              serviceAccount: { create: true }
              rbac: { create: true }
              controller:
                hostNetwork: true
                kind: DaemonSet
                daemonset:
                  useHostPort: true
                # The controller tolerates the etcd and controlplane node-role taints
                tolerations:
                  - key: node-role.kubernetes.io/etcd
                    operator: Exists
                  - key: node-role.kubernetes.io/controlplane
                    operator: Exists
                # But we specifically target controlplane nodes
                nodeSelector:
                  node-role.kubernetes.io/controlplane: "true"
                # We are using the host network, so just create a ClusterIP service
                service:
                  type: ClusterIP
                # Make sure to use the RollingUpdate update strategy
                updateStrategy:
                  type: RollingUpdate
      when: inventory_hostname == ansible_play_hosts[0]

    # On the controlplane hosts, open ports 80 and 443
    - name: Open HTTP(S) ports for ingress controller
      firewalld:
        service: "{{ item }}"
        permanent: true
        immediate: true
        state: enabled
      loop: [http, https]
      when: "'controlplane' in rke_node_roles"
